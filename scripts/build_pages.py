#!/usr/bin/env python3
"""Build static site for the megarepo: one page per subrepo.

Heuristics:
- Walk directories up to a max depth
- A "subrepo" is a directory containing README.md and at least one of: pyproject.toml, package.json, setup.cfg, src/, tests/
- For each subrepo, render README.md (or docs/index.md) to HTML and write `site/<slug>/index.html`
- Generate a top-level index with links
"""
import os
import re
import sys
import shutil
from pathlib import Path
import markdown

ROOT = Path(__file__).resolve().parents[1]
OUT = ROOT / "site"
EXCLUDE_DIRS = {"venv", ".venv", ".git", "node_modules", ".cache", ".github", ".idea", ".vscode"}
MAX_DEPTH = 4

md = markdown.Markdown(extensions=["fenced_code", "codehilite", "tables", "toc"])

def slugify(p: Path) -> str:
    parts = p.relative_to(ROOT).parts
    return "/".join(parts)


def is_candidate(dirpath: Path) -> bool:
    if not (dirpath / "README.md").exists():
        return False
    markers = ["pyproject.toml", "package.json", "setup.cfg", "setup.py"]
    if any((dirpath / m).exists() for m in markers):
        return True
    if (dirpath / "src").is_dir() or (dirpath / "tests").is_dir() or (dirpath / "docs").is_dir():
        return True
    return False


def find_subrepos() -> list[Path]:
    found = []
    for root, dirs, files in os.walk(ROOT):
        # compute depth relative to ROOT
        rel = Path(root).relative_to(ROOT)
        if len(rel.parts) > MAX_DEPTH:
            # don't descend further
            dirs[:] = []
            continue
        # prune excluded dirs
        dirs[:] = [d for d in dirs if d not in EXCLUDE_DIRS]
        p = Path(root)
        # skip the repo root itself so we explore subdirectories
        if p == ROOT:
            continue
        if is_candidate(p):
            found.append(p)
            # don't include nested subrepos beneath this one
            dirs[:] = []
    # deduplicate and sort
    found = sorted(set(found), key=lambda p: str(p))
    return found


TEMPLATE = """<!doctype html>
<html>
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>{title}</title>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css">
  <style>body{{padding:2rem}} pre code {{white-space: pre-wrap;}}</style>
</head>
<body>
<div class="container">
  <nav class="mb-4"><a href="/">Megarepo pages</a> / {breadcrumb}</nav>
  <article>
    {content}
  </article>
  <footer class="mt-5"><hr/><p class="small">Generated by scripts/build_pages.py</p></footer>
</div>
</body>
</html>
"""

INDEX_TEMPLATE = """<!doctype html>
<html>
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Megarepo - Projects</title>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css">
</head>
<body>
<div class="container">
  <h1>Megarepo Projects</h1>
  <p class="lead">Auto-generated index of subprojects (each page is built from README.md or docs/)</p>
  <ul class="list-group">
    {items}
  </ul>
  <footer class="mt-5"><hr/><p class="small">Generated by scripts/build_pages.py</p></footer>
</div>
</body>
</html>
"""


def render_markdown(md_text: str) -> str:
    return md.convert(md_text)


def first_paragraph(md_text: str) -> str:
    # naive: split on double newline
    parts = re.split(r"\n\s*\n", md_text.strip())
    return parts[0] if parts else ""


def build():
    if OUT.exists():
        shutil.rmtree(OUT)
    OUT.mkdir(parents=True, exist_ok=True)

    repos = find_subrepos()
    items_html = []

    for repo in repos:
        rel = repo.relative_to(ROOT)
        slug = slugify(repo)
        out_dir = OUT / rel
        out_dir.mkdir(parents=True, exist_ok=True)

        # pick source: docs/index.md > README.md
        if (repo / "docs" / "index.md").exists():
            src = repo / "docs" / "index.md"
        elif (repo / "README.md").exists():
            src = repo / "README.md"
        else:
            print(f"Skipping {repo} (no source)")
            continue

        md_text = src.read_text(encoding="utf-8")
        html = render_markdown(md_text)
        title = f"{rel}"
        breadcrumb = f"{rel}"
        page = TEMPLATE.format(title=title, breadcrumb=breadcrumb, content=html)
        (out_dir / "index.html").write_text(page, encoding="utf-8")

        excerpt = first_paragraph(md_text)
        items_html.append(f'<li class="list-group-item"><a href="{slug}/">{rel}</a><p class="mb-0">{excerpt}</p></li>')

    index = INDEX_TEMPLATE.format(items='\n'.join(items_html))
    (OUT / "index.html").write_text(index, encoding="utf-8")

    print(f"Generated {len(repos)} pages in {OUT}")


if __name__ == "__main__":
    build()
